{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "import autogen\n",
    "import json\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "print(\"üéØ SupportFlow - AutoGen Customer Support Hub\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Automating customer support with multi-agent collaboration\")\n",
    "print(\"‚úÖ Using local Ollama with llama3.2 - No API keys required!\")\n",
    "\n",
    "# Check if Ollama is available and llama3.2 is installed\n",
    "def check_ollama_setup():\n",
    "    try:\n",
    "        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"\\nüìã Available Ollama models:\")\n",
    "            print(result.stdout)\n",
    "            if 'llama3.2' in result.stdout:\n",
    "                print(\"‚úÖ llama3.2 is available and ready!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå llama3.2 not found. Install it with: ollama pull llama3.2\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"‚ùå Error checking Ollama: {result.stderr}\")\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Ollama not found. Please install: https://ollama.ai/download\")\n",
    "        return False\n",
    "\n",
    "ollama_ready = check_ollama_setup()\n",
    "if not ollama_ready:\n",
    "    print(\"\\nüö® SETUP REQUIRED:\")\n",
    "    print(\"1. Install Ollama: https://ollama.ai/download\")\n",
    "    print(\"2. Pull llama3.2: ollama pull llama3.2\")\n",
    "    print(\"3. Start Ollama: ollama serve\")\n",
    "    print(\"4. Re-run this cell to verify\")\n",
    "else:\n",
    "    print(\"\\nüöÄ Ready to build with local AI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AutoGen with local Ollama\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"llama3.2\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",  # Ollama doesn't need a real API key\n",
    "        \"temperature\": 0.3,  # Lower temperature for consistent support responses\n",
    "        \"price\": [0, 0]\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "print(\"üîß AutoGen configuration ready\")\n",
    "print(f\"Model: Ollama llama3.2 (local)\")\n",
    "print(f\"Base URL: http://localhost:11434/v1\")\n",
    "print(f\"Temperature: 0.3 (for consistent support responses)\")\n",
    "print(f\"‚úÖ No API costs - runs completely local!\")\n",
    "print(f\"üîí Privacy-first - all data stays on your machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Triage Agent - Categorizes and prioritizes tickets\n",
    "triage_agent = autogen.AssistantAgent(\n",
    "    name=\"TriageSpecialist\",\n",
    "    system_message=\"\"\"You are a Customer Support Triage Specialist for CloudTech Solutions.\n",
    "\n",
    "    RESPONSIBILITIES:\n",
    "    - Analyze customer tickets and categorize them\n",
    "    - Assign priority levels (High/Medium/Low)\n",
    "    - Identify the issue type (Technical, Billing, Account, Feature Request)\n",
    "    \n",
    "    CATEGORIES:\n",
    "    - Technical: Login issues, API errors, performance problems\n",
    "    - Billing: Payment questions, invoice issues, subscription changes\n",
    "    - Account: Access problems, user management, permissions\n",
    "    - Feature Request: New functionality requests, improvements\n",
    "    \n",
    "    PRIORITY LEVELS:\n",
    "    - High: Service outages, payment failures, security issues\n",
    "    - Medium: Feature questions, minor bugs, account updates\n",
    "    - Low: General questions, documentation requests, suggestions\n",
    "    \n",
    "    Always respond in this format:\n",
    "    Category: [Technical/Billing/Account/Feature Request]\n",
    "    Priority: [High/Medium/Low]\n",
    "    Reasoning: [Brief explanation]\n",
    "    Next Action: [What type of research/response is needed]\n",
    "    \"\"\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Triage Agent created\")\n",
    "print(\"   üéØ Specializes in ticket categorization and prioritization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Research Agent - Finds solutions and relevant information\n",
    "research_agent = autogen.AssistantAgent(\n",
    "    name=\"ResearchSpecialist\",\n",
    "    system_message=\"\"\"You are a Customer Support Research Specialist for CloudTech Solutions.\n",
    "\n",
    "    RESPONSIBILITIES:\n",
    "    - Research solutions for categorized customer issues\n",
    "    - Reference CloudTech's knowledge base and documentation\n",
    "    - Provide technical solutions and troubleshooting steps\n",
    "    - Gather relevant information for response crafting\n",
    "    \n",
    "    KNOWLEDGE BASE (CloudTech Solutions):\n",
    "    - API Documentation: https://docs.cloudtech.com/api\n",
    "    - Billing Portal: https://billing.cloudtech.com\n",
    "    - Status Page: https://status.cloudtech.com\n",
    "    - User Guide: https://help.cloudtech.com\n",
    "    - Contact: support@cloudtech.com, Phone: 1-800-CLOUD-99\n",
    "    \n",
    "    COMMON SOLUTIONS:\n",
    "    - Login Issues: Check 2FA, password reset, browser cache\n",
    "    - API Errors: Verify API key, check rate limits, review documentation\n",
    "    - Billing: Direct to billing portal, provide contact for complex issues\n",
    "    - Account Access: Verify permissions, check user roles\n",
    "    \n",
    "    Always provide:\n",
    "    1. Root cause analysis\n",
    "    2. Step-by-step solution\n",
    "    3. Relevant documentation links\n",
    "    4. Escalation path if needed\n",
    "    \"\"\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Research Agent created\")\n",
    "print(\"   üîç Specializes in solution research and troubleshooting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Response Agent - Crafts professional customer responses\n",
    "response_agent = autogen.AssistantAgent(\n",
    "    name=\"ResponseSpecialist\",\n",
    "    system_message=\"\"\"You are a Customer Support Response Specialist for CloudTech Solutions.\n",
    "\n",
    "    RESPONSIBILITIES:\n",
    "    - Craft professional, empathetic customer responses\n",
    "    - Include all solution steps and relevant links\n",
    "    - Maintain CloudTech's friendly, helpful tone\n",
    "    - Ensure responses are complete and actionable\n",
    "    \n",
    "    RESPONSE GUIDELINES:\n",
    "    - Start with empathy and acknowledgment\n",
    "    - Provide clear, step-by-step solutions\n",
    "    - Include relevant documentation links\n",
    "    - Offer additional assistance\n",
    "    - Professional but warm tone\n",
    "    - Use CloudTech branding elements\n",
    "    \n",
    "    TEMPLATE STRUCTURE:\n",
    "    1. Greeting and acknowledgment\n",
    "    2. Solution steps (numbered if multiple)\n",
    "    3. Additional resources\n",
    "    4. Follow-up offer\n",
    "    5. Professional closing\n",
    "    \n",
    "    Always ensure responses are:\n",
    "    - Complete and actionable\n",
    "    - Easy to understand\n",
    "    - Include next steps\n",
    "    - Maintain helpful tone\n",
    "    \"\"\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Response Agent created\")\n",
    "print(\"   ‚úçÔ∏è Specializes in professional customer communication\")\n",
    "print(\"\\nüéâ Support agent team ready for action!\")\n",
    "print(\"   Team: Triage ‚Üí Research ‚Üí Response\")\n",
    "print(\"   Powered by: Local Ollama llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_support_ticket(customer_ticket):\n",
    "    \"\"\"Process a customer support ticket through our agent workflow\"\"\"\n",
    "    \n",
    "    print(f\"\\nüé´ NEW SUPPORT TICKET\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Customer Message: {customer_ticket}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Step 1: Triage the ticket\n",
    "    print(\"\\nüéØ STEP 1: Ticket Triage (Local AI Processing...)\")\n",
    "    triage_response = triage_agent.generate_reply(\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Please triage this customer ticket: {customer_ticket}\"}]\n",
    "    )\n",
    "    print(f\"Triage Analysis: {triage_response}\")\n",
    "    \n",
    "    # Step 2: Research solutions\n",
    "    print(\"\\nüîç STEP 2: Solution Research (Local AI Processing...)\")\n",
    "    research_response = research_agent.generate_reply(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Research solutions for this ticket: {customer_ticket}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Triage analysis: {triage_response}\"}\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Research Results: {research_response}\")\n",
    "    \n",
    "    # Step 3: Craft customer response\n",
    "    print(\"\\n‚úçÔ∏è STEP 3: Customer Response (Local AI Processing...)\")\n",
    "    customer_response = response_agent.generate_reply(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Draft a professional response for: {customer_ticket}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Research: {research_response}\"}\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Final Response: {customer_response}\")\n",
    "    \n",
    "    return {\n",
    "        \"ticket\": customer_ticket,\n",
    "        \"triage\": triage_response,\n",
    "        \"research\": research_response,\n",
    "        \"response\": customer_response,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "print(\"üîß Support ticket processing function ready\")\n",
    "print(\"   Workflow: Customer Ticket ‚Üí Triage ‚Üí Research ‚Üí Response\")\n",
    "print(\"   AI Engine: Local Ollama llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: Technical Issue\n",
    "print(\"üß™ DEMO 1: Technical Support Issue\")\n",
    "ticket1 = \"I'm getting API error 401 when trying to authenticate. My API key worked yesterday but now it's failing. Can you help?\"\n",
    "\n",
    "result1 = process_support_ticket(ticket1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Billing Question\n",
    "print(\"üß™ DEMO 2: Billing Inquiry\")\n",
    "ticket2 = \"I was charged twice this month for my subscription. My invoice shows two payments but I only have one account. Please refund the extra charge.\"\n",
    "\n",
    "result2 = process_support_ticket(ticket2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 3: High Priority Issue\n",
    "print(\"üß™ DEMO 3: High Priority Service Issue\")\n",
    "ticket3 = \"Our entire team can't log in to CloudTech. We're getting 'service unavailable' errors. This is blocking our whole company!\"\n",
    "\n",
    "result3 = process_support_ticket(ticket3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_support_demo():\n",
    "    \"\"\"Demonstrate agents collaborating on a complex multi-faceted issue\"\"\"\n",
    "    \n",
    "    complex_ticket = \"\"\"\n",
    "    Hi CloudTech Support,\n",
    "    \n",
    "    We're having multiple issues:\n",
    "    1. Our API calls are returning 500 errors intermittently\n",
    "    2. We were double-charged on our invoice this month\n",
    "    3. We need to add 5 new team members but can't access user management\n",
    "    4. Is there a way to get real-time status updates?\n",
    "    \n",
    "    This is urgent as it's affecting our production system.\n",
    "    \n",
    "    Thanks,\n",
    "    Sarah Chen, CTO at TechStartup Inc\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üö® COMPLEX MULTI-ISSUE TICKET\")\n",
    "    print(\"=\" * 40)\n",
    "    print(complex_ticket)\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create a group chat for agent collaboration\n",
    "    groupchat = autogen.GroupChat(\n",
    "        agents=[triage_agent, research_agent, response_agent],\n",
    "        messages=[],\n",
    "        max_round=8\n",
    "    )\n",
    "    \n",
    "    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "    \n",
    "    # Start collaborative resolution\n",
    "    print(\"\\nüë• AGENTS COLLABORATING WITH LOCAL AI...\")\n",
    "    print(\"Watch how the agents work together using Ollama llama3.2:\")\n",
    "    \n",
    "    triage_agent.initiate_chat(\n",
    "        manager,\n",
    "        message=f\"\"\"We have a complex customer ticket with multiple issues. \n",
    "        Let's work together to provide a comprehensive solution.\n",
    "        \n",
    "        Customer Ticket: {complex_ticket}\n",
    "        \n",
    "        Triage Agent: Please categorize and prioritize each issue.\n",
    "        Research Agent: Find solutions for each identified problem.\n",
    "        Response Agent: Craft a comprehensive response addressing all issues.\n",
    "        \"\"\",\n",
    "        max_turns=6\n",
    "    )\n",
    "\n",
    "# Run the collaborative demo\n",
    "print(\"üîÑ Starting multi-agent collaboration demo...\")\n",
    "collaborative_support_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
